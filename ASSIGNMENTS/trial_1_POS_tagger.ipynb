{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRF based tagger of Code-Mixed text\n",
    "\n",
    "This tutorial utilizes the `python-crfsuite` for modeling Conditional Random Fields. Most of the code is from the tutorial on [NER using CRFs](https://github.com/scrapinghub/python-crfsuite/blob/master/examples/CoNLL%202002.ipynb). This is a demo for sequence labeling tasks like language labeling and POS tagger.\n",
    "\n",
    "Installation requirements:\n",
    "\n",
    "* nltk (if already not installed: use `pip install nltk`)\n",
    "* scikit-learn (if already not installed: `pip install sklearn`)\n",
    "* python-crfsuite (`pip install python-crfsuite`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import nltk\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import sklearn\n",
    "import pycrfsuite\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading raw text data from [ICON 2016 shared contest](http://amitavadas.com/Code-Mixing.html) on POS tagging of social media text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(files):\n",
    "    data, sent = [], []\n",
    "    for file in files:\n",
    "        with open(file, 'r') as rf:\n",
    "            for line in rf:\n",
    "                if line.strip() != '':\n",
    "                    # Note: the shared corpus is already tokenized\n",
    "                    sent.append(line.strip().split('\\t'))\n",
    "                else:\n",
    "                    if len(sent) > 0:\n",
    "                        data.append(sent)\n",
    "                        sent = []\n",
    "    return data\n",
    "\n",
    "sents = load_data(['data/FB_HI_EN_CR.txt', 'data/TWT_HI_EN_CR.txt', 'data/WA_HI_EN_CR.txt',\n",
    "                   'data/FB_BN_EN_CR.txt', 'data/TWT_BN_EN_CR.txt', 'data/WA_BN_EN_CR.txt',\n",
    "                   'data/FB_TE_EN_CR.txt', 'data/TWT_TE_EN_CR.txt', 'data/WA_TE_EN_CR.txt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a train and validation split. Here, we are first randomly shuffling the entire corpus and use the first 80% of the instances as train and the remaining as validation. Random seed is set to allow for reproduction of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train sentences: 4186\n",
      "# Validation sentences: 1047\n"
     ]
    }
   ],
   "source": [
    "# random.seed(7)\n",
    "random.shuffle(sents)\n",
    "train_sents = sents[:int(0.8*len(sents))]\n",
    "valid_sents = sents[int(0.8*len(sents)):]\n",
    "print(\"# Train sentences: %d\" % (len(train_sents)))\n",
    "print(\"# Validation sentences: %d\" % (len(valid_sents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample train data with language labels and POS tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Gn', 'hi', 'U']]\n"
     ]
    }
   ],
   "source": [
    "print(train_sents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting features\n",
    "\n",
    "Now we extract some features from the raw text data to pass onto the CRF model \n",
    "\n",
    "* Current word\n",
    "* Character n-grams of the current word\n",
    "* Context\n",
    "    * Previous word\n",
    "* Begin and End of sentence markers (BOS and EOS)\n",
    "\n",
    "Note: Please feel free to explore other features as described in lectures and other reading material that can be of help to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, k):\n",
    "    word = sent[k][0]\n",
    "    features = [\n",
    "        'token=%s' % (word)\n",
    "    ]\n",
    "    # extracting n-grams, for n=1 to 5\n",
    "    for i in range(1,6):\n",
    "        # if the value of n is greater than the word length, we exit the loop\n",
    "        if i > len(word):\n",
    "            break\n",
    "        character_features = [word[j:j+i] for j in range(len(word)-i+1)]\n",
    "        features.extend([\n",
    "            # is count of individual n-grams important? is the order important?\n",
    "            \"char-%d-gram=%s\" % (i, ' '.join(list(set(character_features))))\n",
    "        ])\n",
    "    if k == 0:\n",
    "        # first word in the sentence\n",
    "        features.append('BOS')\n",
    "    else:\n",
    "        features.extend([\n",
    "            \"-1:word=%s\" % (sent[k-1][0])\n",
    "        ])\n",
    "    if i == len(sent):\n",
    "        # last word in the sentence         \n",
    "        features.append('EOS')\n",
    " \n",
    "    return features\n",
    "        \n",
    "def sent2features(sent):\n",
    "    # generating features for all the words/tokens in a sentence `sent`    \n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2langs(sent):\n",
    "    return [language_label for token, language_label, pos_tag in sent]\n",
    "\n",
    "def sent2pos(sent):\n",
    "    return [pos_tag for token, language_label, pos_tag in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, language_label, pos_tag in sent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating these features from train and validation data. If you are building a language identification model, the y_train and y_test should be language labels (`sent2langs`), and if you are learning a pos-tagger, these should contain pos-tags (`sent2pos`) as shown in the below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.03 s, sys: 24.5 ms, total: 1.06 s\n",
      "Wall time: 1.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = [sent2features(sent) for sent in train_sents]\n",
    "# y_train = [sent2langs(sent) for sent in train_sents]\n",
    "# for training a pos-tagging system\n",
    "y_train = [sent2pos(sent) for sent in train_sents]\n",
    "\n",
    "X_test = [sent2features(sent) for sent in valid_sents]\n",
    "# y_test = [sent2langs(sent) for sent in valid_sents]\n",
    "y_test = [sent2pos(sent) for sent in valid_sents]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View a sample of train data with their corresponding features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Preparing the CRF model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.18 s, sys: 21.8 ms, total: 1.2 s\n",
      "Wall time: 1.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer = pycrfsuite.Trainer(verbose=True)\n",
    "\n",
    "for xseq, yseq in zip(X_train, y_train):\n",
    "    trainer.append(xseq, yseq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting training parameters for the CRF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.set_params({\n",
    "    'c1': 1.0,   # coefficient for L1 penalty\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 50,  # stop earlier\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 1\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 144439\n",
      "Seconds required: 0.775\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 1.000000\n",
      "c2: 0.001000\n",
      "num_memories: 6\n",
      "max_iterations: 50\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "***** Iteration #1 *****\n",
      "Loss: 184944.424686\n",
      "Feature norm: 1.000000\n",
      "Error norm: 12483.045187\n",
      "Active features: 45909\n",
      "Line search trials: 1\n",
      "Line search step: 0.000078\n",
      "Seconds required for this iteration: 0.169\n",
      "\n",
      "***** Iteration #2 *****\n",
      "Loss: 158459.145080\n",
      "Feature norm: 5.659668\n",
      "Error norm: 34159.864001\n",
      "Active features: 45871\n",
      "Line search trials: 4\n",
      "Line search step: 0.125000\n",
      "Seconds required for this iteration: 0.313\n",
      "\n",
      "***** Iteration #3 *****\n",
      "Loss: 145972.613679\n",
      "Feature norm: 4.888285\n",
      "Error norm: 7962.356410\n",
      "Active features: 45710\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.086\n",
      "\n",
      "***** Iteration #4 *****\n",
      "Loss: 138282.308349\n",
      "Feature norm: 6.304775\n",
      "Error norm: 5996.841129\n",
      "Active features: 45677\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.086\n",
      "\n",
      "***** Iteration #5 *****\n",
      "Loss: 124371.477663\n",
      "Feature norm: 10.005644\n",
      "Error norm: 4834.347709\n",
      "Active features: 44523\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.084\n",
      "\n",
      "***** Iteration #6 *****\n",
      "Loss: 115557.000636\n",
      "Feature norm: 13.170467\n",
      "Error norm: 2930.221542\n",
      "Active features: 44989\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.083\n",
      "\n",
      "***** Iteration #7 *****\n",
      "Loss: 107311.190338\n",
      "Feature norm: 17.205361\n",
      "Error norm: 2683.876966\n",
      "Active features: 44395\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.084\n",
      "\n",
      "***** Iteration #8 *****\n",
      "Loss: 96209.444087\n",
      "Feature norm: 25.544172\n",
      "Error norm: 1958.798243\n",
      "Active features: 43325\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.085\n",
      "\n",
      "***** Iteration #9 *****\n",
      "Loss: 89241.646640\n",
      "Feature norm: 33.243941\n",
      "Error norm: 2440.374170\n",
      "Active features: 42916\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.083\n",
      "\n",
      "***** Iteration #10 *****\n",
      "Loss: 82758.673290\n",
      "Feature norm: 41.347686\n",
      "Error norm: 2007.249466\n",
      "Active features: 42858\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.087\n",
      "\n",
      "***** Iteration #11 *****\n",
      "Loss: 78758.231427\n",
      "Feature norm: 50.101221\n",
      "Error norm: 5369.001174\n",
      "Active features: 42738\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.091\n",
      "\n",
      "***** Iteration #12 *****\n",
      "Loss: 75357.557686\n",
      "Feature norm: 56.816785\n",
      "Error norm: 3106.525101\n",
      "Active features: 43922\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.083\n",
      "\n",
      "***** Iteration #13 *****\n",
      "Loss: 73890.320970\n",
      "Feature norm: 58.649274\n",
      "Error norm: 1863.151078\n",
      "Active features: 43669\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.083\n",
      "\n",
      "***** Iteration #14 *****\n",
      "Loss: 71221.313046\n",
      "Feature norm: 65.324729\n",
      "Error norm: 965.056928\n",
      "Active features: 43004\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.090\n",
      "\n",
      "***** Iteration #15 *****\n",
      "Loss: 69510.579617\n",
      "Feature norm: 70.051604\n",
      "Error norm: 630.792835\n",
      "Active features: 42730\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.084\n",
      "\n",
      "***** Iteration #16 *****\n",
      "Loss: 67091.722302\n",
      "Feature norm: 79.778898\n",
      "Error norm: 879.501572\n",
      "Active features: 41783\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.082\n",
      "\n",
      "***** Iteration #17 *****\n",
      "Loss: 66993.097757\n",
      "Feature norm: 85.581581\n",
      "Error norm: 2893.537013\n",
      "Active features: 41023\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.091\n",
      "\n",
      "***** Iteration #18 *****\n",
      "Loss: 65303.893882\n",
      "Feature norm: 86.748490\n",
      "Error norm: 698.593873\n",
      "Active features: 41226\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.084\n",
      "\n",
      "***** Iteration #19 *****\n",
      "Loss: 64747.707151\n",
      "Feature norm: 88.367401\n",
      "Error norm: 361.926025\n",
      "Active features: 40952\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.084\n",
      "\n",
      "***** Iteration #20 *****\n",
      "Loss: 63783.364484\n",
      "Feature norm: 92.796351\n",
      "Error norm: 398.654423\n",
      "Active features: 40222\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.084\n",
      "\n",
      "***** Iteration #21 *****\n",
      "Loss: 63606.720850\n",
      "Feature norm: 93.679847\n",
      "Error norm: 1839.371997\n",
      "Active features: 39933\n",
      "Line search trials: 3\n",
      "Line search step: 0.250000\n",
      "Seconds required for this iteration: 0.236\n",
      "\n",
      "***** Iteration #22 *****\n",
      "Loss: 62830.133172\n",
      "Feature norm: 96.043482\n",
      "Error norm: 510.534781\n",
      "Active features: 39548\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.083\n",
      "\n",
      "***** Iteration #23 *****\n",
      "Loss: 62256.245980\n",
      "Feature norm: 99.061619\n",
      "Error norm: 360.419639\n",
      "Active features: 38790\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.090\n",
      "\n",
      "***** Iteration #24 *****\n",
      "Loss: 61792.128976\n",
      "Feature norm: 101.626655\n",
      "Error norm: 290.782329\n",
      "Active features: 38178\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.096\n",
      "\n",
      "***** Iteration #25 *****\n",
      "Loss: 61490.796732\n",
      "Feature norm: 103.853649\n",
      "Error norm: 784.487828\n",
      "Active features: 37543\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 0.187\n",
      "\n",
      "***** Iteration #26 *****\n",
      "Loss: 61144.087017\n",
      "Feature norm: 105.720999\n",
      "Error norm: 298.044079\n",
      "Active features: 37146\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.083\n",
      "\n",
      "***** Iteration #27 *****\n",
      "Loss: 60892.628882\n",
      "Feature norm: 107.668359\n",
      "Error norm: 160.539001\n",
      "Active features: 36567\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.083\n",
      "\n",
      "***** Iteration #28 *****\n",
      "Loss: 60626.826144\n",
      "Feature norm: 111.851543\n",
      "Error norm: 393.020510\n",
      "Active features: 35602\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.088\n",
      "\n",
      "***** Iteration #29 *****\n",
      "Loss: 60564.721404\n",
      "Feature norm: 112.841362\n",
      "Error norm: 1156.130226\n",
      "Active features: 35133\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 0.161\n",
      "\n",
      "***** Iteration #30 *****\n",
      "Loss: 60432.156994\n",
      "Feature norm: 113.608824\n",
      "Error norm: 367.342321\n",
      "Active features: 34972\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.089\n",
      "\n",
      "***** Iteration #31 *****\n",
      "Loss: 60309.505308\n",
      "Feature norm: 115.121683\n",
      "Error norm: 276.167262\n",
      "Active features: 34492\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.089\n",
      "\n",
      "***** Iteration #32 *****\n",
      "Loss: 60202.764078\n",
      "Feature norm: 116.544899\n",
      "Error norm: 318.037791\n",
      "Active features: 33932\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.089\n",
      "\n",
      "***** Iteration #33 *****\n",
      "Loss: 60107.797635\n",
      "Feature norm: 119.746913\n",
      "Error norm: 534.435067\n",
      "Active features: 32426\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.099\n",
      "\n",
      "***** Iteration #34 *****\n",
      "Loss: 59973.286212\n",
      "Feature norm: 120.361581\n",
      "Error norm: 358.227267\n",
      "Active features: 32236\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.089\n",
      "\n",
      "***** Iteration #35 *****\n",
      "Loss: 59930.961360\n",
      "Feature norm: 120.638477\n",
      "Error norm: 212.064895\n",
      "Active features: 32209\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.089\n",
      "\n",
      "***** Iteration #36 *****\n",
      "Loss: 59890.615744\n",
      "Feature norm: 121.052268\n",
      "Error norm: 104.999308\n",
      "Active features: 32019\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.084\n",
      "\n",
      "***** Iteration #37 *****\n",
      "Loss: 59796.065939\n",
      "Feature norm: 123.154664\n",
      "Error norm: 178.193165\n",
      "Active features: 31246\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.085\n",
      "\n",
      "***** Iteration #38 *****\n",
      "Loss: 59753.673651\n",
      "Feature norm: 124.839675\n",
      "Error norm: 636.070138\n",
      "Active features: 30808\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.087\n",
      "\n",
      "***** Iteration #39 *****\n",
      "Loss: 59676.248907\n",
      "Feature norm: 125.870486\n",
      "Error norm: 161.031139\n",
      "Active features: 30709\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.086\n",
      "\n",
      "***** Iteration #40 *****\n",
      "Loss: 59631.188452\n",
      "Feature norm: 127.139607\n",
      "Error norm: 91.810186\n",
      "Active features: 30452\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.084\n",
      "\n",
      "***** Iteration #41 *****\n",
      "Loss: 59581.443071\n",
      "Feature norm: 129.083376\n",
      "Error norm: 169.349714\n",
      "Active features: 29864\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.087\n",
      "\n",
      "***** Iteration #42 *****\n",
      "Loss: 59544.989489\n",
      "Feature norm: 129.840311\n",
      "Error norm: 180.081283\n",
      "Active features: 29688\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.084\n",
      "\n",
      "***** Iteration #43 *****\n",
      "Loss: 59520.475078\n",
      "Feature norm: 130.028039\n",
      "Error norm: 87.990730\n",
      "Active features: 29581\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.084\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Iteration #44 *****\n",
      "Loss: 59484.698474\n",
      "Feature norm: 130.642568\n",
      "Error norm: 120.763590\n",
      "Active features: 29274\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.083\n",
      "\n",
      "***** Iteration #45 *****\n",
      "Loss: 59456.445504\n",
      "Feature norm: 131.059697\n",
      "Error norm: 202.832362\n",
      "Active features: 29099\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.088\n",
      "\n",
      "***** Iteration #46 *****\n",
      "Loss: 59431.407720\n",
      "Feature norm: 131.486823\n",
      "Error norm: 307.707884\n",
      "Active features: 28903\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.086\n",
      "\n",
      "***** Iteration #47 *****\n",
      "Loss: 59405.157022\n",
      "Feature norm: 131.935112\n",
      "Error norm: 101.385246\n",
      "Active features: 28739\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.082\n",
      "\n",
      "***** Iteration #48 *****\n",
      "Loss: 59383.653193\n",
      "Feature norm: 132.224912\n",
      "Error norm: 81.017232\n",
      "Active features: 28636\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.082\n",
      "\n",
      "***** Iteration #49 *****\n",
      "Loss: 59362.484692\n",
      "Feature norm: 132.702470\n",
      "Error norm: 110.818381\n",
      "Active features: 28452\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.082\n",
      "\n",
      "***** Iteration #50 *****\n",
      "Loss: 59347.423677\n",
      "Feature norm: 133.146475\n",
      "Error norm: 196.734176\n",
      "Active features: 28303\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.082\n",
      "\n",
      "L-BFGS terminated with the maximum number of iterations\n",
      "Total seconds required for training: 4.935\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 28303 (144439)\n",
      "Number of active attributes: 23387 (113616)\n",
      "Number of active labels: 18 (18)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.115\n",
      "\n",
      "CPU times: user 5.7 s, sys: 142 ms, total: 5.84 s\n",
      "Wall time: 5.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train('test1.crfsuite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a tagger and loading the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x1a24772390>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('test1.crfsuite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making predictions on the validation data using the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@news24tvchannel very good Virat and m.s Dhoni aap ko aur puri team ko bahut bahut badhaiya\n",
      "\n",
      "Predicted: @ G_R G_J G_N CC G_N G_N G_X PSP DT G_N G_N PSP G_N G_N G_N\n",
      "Correct:   @ G_R G_J G_N CC G_N G_N G_X PSP DT G_N G_X PSP G_N G_N G_N\n"
     ]
    }
   ],
   "source": [
    "example_sent = valid_sents[56]\n",
    "print(' '.join(sent2tokens(example_sent)), end='\\n\\n')\n",
    "\n",
    "print(\"Predicted:\", ' '.join(tagger.tag(sent2features(example_sent))))\n",
    "print(\"Correct:  \", ' '.join(sent2pos(example_sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['G_J', 'G_X', 'DT', '@', 'CC', 'G_R', 'PSP', 'G_N']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = sent2pos(example_sent)\n",
    "y_pred = tagger.tag(sent2features(example_sent))\n",
    "t = set(y_true)\n",
    "t = list(t)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 2, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 7]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true, y_pred, labels=t )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_t = []\n",
    "y_true_t = []\n",
    "for valids in valid_sents:\n",
    "    y_pred_t.extend(tagger.tag(sent2features(valids)))\n",
    "    y_true_t.extend(sent2pos(valids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  77,    0,    1,    8,    0,    1,   10,    0,    0,    0,    0,\n",
       "           0,    0,    1,    1,    0,   40,    0],\n",
       "       [   1,  418,    0,   11,    8,    0,    6,    3,    5,    0,    0,\n",
       "           5,   14,   27,    0,    3,  333,    0],\n",
       "       [   2,    0,  111,    8,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,   25,    0],\n",
       "       [   5,    3,    3, 2138,    6,    0,    7,    4,   13,    1,    1,\n",
       "          42,    3,   29,    1,   30,  565,    0],\n",
       "       [   0,    1,    0,    4,  388,    0,    0,    1,    3,    1,    0,\n",
       "          18,    0,    4,    0,    1,   29,    0],\n",
       "       [   0,    1,    0,   14,    0,    0,    0,    0,    0,    0,    0,\n",
       "           2,    0,    0,    0,    0,   19,   10],\n",
       "       [   3,    1,    1,    0,    0,    0,  245,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    1,  262,    0],\n",
       "       [   1,   12,    0,    1,    0,    0,    0,   63,    5,    0,    0,\n",
       "           8,    0,    8,    0,    1,   37,   10],\n",
       "       [   1,    0,    0,   15,    6,    0,    6,    4,  211,    5,    0,\n",
       "          10,    5,   11,    0,   31,  127,    0],\n",
       "       [   1,    0,    0,    1,    7,    0,    0,    1,    9,  185,    0,\n",
       "           0,    0,    1,    0,   46,   23,    0],\n",
       "       [   0,    0,    0,   14,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    5,    0,    0,    0,    0,    0],\n",
       "       [   0,    7,    0,   44,   21,    0,    3,    3,    4,    2,    0,\n",
       "         808,    3,   21,    0,   32,  191,    0],\n",
       "       [   0,   12,    0,    9,    3,    0,    1,    3,    5,    0,    0,\n",
       "           9,  294,   14,    0,   10,  115,    1],\n",
       "       [   1,   21,    0,   49,    8,    0,    9,    3,   21,    2,    0,\n",
       "          13,   10, 1401,    1,   18,  760,    1],\n",
       "       [   7,    0,    0,    4,    0,    0,    9,    0,    0,    0,    0,\n",
       "           0,    0,    5,   80,    0,  101,    1],\n",
       "       [   0,    1,    0,   30,   14,    0,    0,    0,   23,   41,    0,\n",
       "          88,   11,   21,    0,  677,  114,    3],\n",
       "       [   2,   37,    1,  136,    9,    0,   62,   11,   32,    2,    0,\n",
       "          71,   10,  177,    4,   27, 5143,    1],\n",
       "       [   0,    2,    0,    2,    0,    2,    0,    0,    0,    0,    0,\n",
       "           1,    0,    0,    3,    0,   76,   92]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = set(y_true_t)\n",
    "t = list(t)\n",
    "confusion_matrix(y_true_t, y_pred_t, labels=t )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
